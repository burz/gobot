%
% File finalReport.tex
%
% Contact: aburzil1@jhu.edu

\documentclass[11pt,letterpaper]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{naaclhlt2010}
\usepackage{times}
\usepackage{latexsym}
\setlength\titlebox{6.5cm}    % Expanding the titlebox

\title{Attempting a Machine Learning Solution for Scoring the Game of Go}

\author{Anthony Burzillo\\
  Johns Hopkins University\\
  2914 North Calvert St.\\
  Baltimore, MD 21218, USA\\
  {\tt aburzil1@jhu.edu}}

\date{}

\begin{document}

\maketitle

\begin{abstract}
  This document explains how the author generated features and designed a learning algorithm to score the final board in the
  game of Go. Furthermore, the reader will observe that the algorithm was inadequate to solve the scoring problem.
\end{abstract}

\section{Introduction}

Go is a board game typically played on a $19 \times 19$ board between two players, white and black. Each player, starting with
black, successively places stones on the intersections of the board until either both of the players agree that the game is over
or until one player resigns. The outcome of the game is determined by the number of empty intersections that each player has
surrounded. These empty intersections are known as the territory surrounded by the player.

Because of the grid each stone, except possibly on the edge of the board, has 4 intersections that it connects to. We call these
intersections liberties. When for any stone all liberties are covered by opponent stones then we say that the stone is captured and
it is removed from the board and counted as a point for the opponent. If two or more stones are connected, they can be captured
only by covering all of the liberties of the collective group by opponent stones. Due to this fact, each player can construct groups
that cannot be captured by surrounding two non-connected territories within the group. Then the opponent cannot possibly cover
the liberties in both territories without committing suicide, which is not allowed. We call each of these non-connected territories
eyes and any group with two or more alive, a group with fewer than two eyes is dead.

The main problem of scoring is determining the life and death of groups of stones on the board. This is a nontrivial problem
because the life and death of groups is not always obvious. For instance one position that can occur is when two groups of
different colors each have only two liberties but they are shared between the group. Then if one player were to play in one of
those liberties the other player would be able to immediately capture that player's stones. This situation is called a seki, and
commonly occurs in games. The problem that this example shows is that the question of life and death is not local, instead it
depends largely on the area around the group. If either player were able to capture one of the groups around his stones stuck in
seki he will be able to capture his opponents stones.

To actually score a board all that is needed to do is to (1) determine life and death of all groups, (2) remove dead groups from
the board, (3) sum up all territory that is completely surrounded by each player, (4) add the points from captured stones to each
players score, and (5) add to white's score the komi, i.e. the points awarded to him for having to take the second turn. This
problem is hard to do with a deterministic algorithm constructed by a human, so therefore it naturally lends itself to a machine
learning solution.

In the paper \emph{Learning to score final positions in the game of Go} \cite{vdW:04}, the authors describe how they were able
to craft an accurate scorer for go using manually labeled life and death information for groups in final positions. This is tedious
since the lack of an accurate scorer disallows easy labeling. Therefore, in this project the author tried to develop a scorer that
did not rely on this specific to group labeling but instead depend only on the labeling of the final score. Then an energy function
could be created which determined the accuracy of the estimator versus the actual final score.

\section{Board Representation}

In order to obtain the final board that we need to score the game we must run through 

\section{Feature Generation}

Feature generation turns out to be a costly process for this application. We need to generate features for each block of stones in
the final position. A block is a group of stones that are directly connected, i.e. each stone in the block is on an intersection directly
next to another stone in the block. Since we know that the life of any group depends not only on the state of the block but also
the state of the board surrounding the stone, we must make sure to include features that describe both states. In this program
we chose to use a slightly different feature set then that in \cite{vdW:04}. Specifically we include 46 features for each block:
First the local features
\begin{itemize}
  \item The size of the block.
  \item The perimeter of the block, i.e. the number of intersections directly next to but not in the block.
  \item The number of opponent stones in the perimeter of the block.
  \item The liberties of the block.
  \item The liberties of the block that the opponent should not play, i.e. liberties which if played by the opponent would cause his
    stones to have only 1 liberty or would be suicide.
  \item The liberties of the block that, if played by the player, would cause the block to have 1 liberty.
  \item The number of second-order liberties, i.e. empty intersections directly next to the liberties of the block that are not liberties.
  \item The number of third-order liberties, i.e. liberties of second order liberties.
  \item The number of opponent blocks that are adjacent to the block.
  \item The center of mass, i.e. the average distance of stones from the first and second closest edge of the board.
  \item The size in interior points of the smallest bounding box of the block.
\end{itemize}
Then features for color enclosed territories, i.e. territories surrounded by all one color, adjacent to the block
\begin{itemize}
  \item The number of color enclosed territories.
  \item The size of the color enclosed territories as a sum.
  \item The perimeter of the color enclosed territories.
  \item The center of mass of the color enclosed territories.
\end{itemize}
Then features for eyespace adjacent to the block, which we define to be a color enclosed regions with a size less than 5
\begin{itemize}
  \item The number of eyespace blocks.
  \item The size of the eyespace.
  \item The perimeter of the eyespace.
\end{itemize}
Next we include features for disputed territories adjacent to the block, i.e. territories that are adjacent to blocks of both colors.
\begin{itemize}
  \item The number of disputed territories.
  \item The liberties touching the block in the disputed territories.
  \item The liberties of all friendly blocks in the territories.
  \item The liberties of all enemy blocks in the territories.
\end{itemize}
Then features for the optimistic chain of the block. An optimistic chain is a group of blocks that share liberties with each other.
These chains represent what blocks a player could potentially connect if needed.
\begin{itemize}
  \item Number of blocks in the optimistic chain.
  \item Size of the optimistic chain.
  \item The perimeter of the optimistic chain.
  \item The number of color enclosed regions adjacent to the chain.
  \item The size of the color enclosed regions.
  \item The perimeter of the color enclosed regions.
  \item The center of mass of the color enclosed regions.
  \item The number of eyspaces adjacent to the optimistic chain.
  \item The size of the eyespace.
  \item The perimeter of the eyespace.
  \item The number of disputed territories adjacent to the optimistic chain.
  \item The liberties touching the chain in the disputed territories.
  \item The liberties of all friendly blocks in the territories.
  \item The liberties of all enemy blocks in the territories.
\end{itemize}
Finally we include the following features for each of the weakest and second-weakest enemy blocks adjacent to the block and
the weakest enemy block adjacent to or sharing a liberty with the optimistic chain
\begin{itemize}
  \item The perimeter of the enemy block.
  \item The liberties of the enemy block.
  \item The shared liberties of the block and enemy block (or the chain and the enemy block).
\end{itemize}

Although our algorithm could certainly be optimized further, we were able to rather efficiently compute the features. For instance,
when computing the perimeter we were able to also compute the opponents, liberties, adjacent enemy blocks, center of mass,
and the bounding box size. Furthermore, we cached the features for chains so that the features would only need to be computed
once per chain.

\section{Machine Learning}

For the machine learning portion of the program we decided to use the RPROP gradient descent algorithm as recommended
by \cite{vdW:04}. This turned out to be a poor choice because of the way we defined the scoring and energy functions. Due to
the fact that we did not have enough time to manually a reasonable size of games with labeled blocks, i.e. alive or dead, we
attempted to define a scoring and energy function that depended only on the game itself and a known final score.

\subsection{The Energy Function}

\def\v#1{\mathbf{#1}}
\def\touches#1#2{\mbox{tchs}_{#1}{\left(#2\right)}}
\def\color#1{\mbox{clr}{\left(#1\right)}}
\def\colorp#1{\mbox{clr}^*{\left(#1\right)}}
\def\size#1{\mbox{size}{\left(#1\right)}}

We will define our energy function $E$. Suppose that we have a game with blocks $b_1, \ldots, b_n$, and empty territories
$e_1, \ldots, e_t$ at the end of the game.  and our network's hidden layer has $m$ nodes. Our learning algorithm uses a
hidden layer of size $m$, a matrix of input layer weights $W$ of size $m \times n$, a vector of hidden layer weights
$\v{ v } \in \mathbb{ R }^m$, and two vector biases $\v{ a } \in \mathbb{ R }^n$ and $\v{ b } \in \mathbb{ R }^m$.
Furthermore, for the second half of the algorithm, we use a matrix of weights $V$ of size $4 \times 5$, a vector of hidden
weights $\v{ g } \in \mathbb{ R }^4$, and two bias vectors $\v{ c } \in \mathbb{ R }^5$ and $\v{ d } \in \mathbb{ R }^4$.

Suppose we have a game $G$ for which we would like to determine $E(G)$. Let $k$ be the komi, $p_b$ and $p_w$ the prisoners
held by black and white, respectively, and the true final score $S$. Define $\touches{ e }{ b }$ to be the indicator function
taking the value 1 when the territory $e$ touches the block $b$. Define $\color{ b }$ to be the indicator function taking the
value 1 when the block $b$ is white. Let $\size{ e }$ return the size of the territory $e$. Let $G(x)$ be the
indicator function that returns 1 when $x$ is greater than $x$. Note that when $x \neq 0$,  $G(x) = (|x| + x) / 2x$. The energy
function runs algorithmically as follows:
\begin{enumerate}
  \item For each block $b_i$ calculate a feature vector $\v{ x }_i \in \mathbb{ R }^n$.
  \item Calculate $r_i = \v{ v }[W(\v{ x }_i + \v{ a }) + \v{ b }]$ for each $i$.
  \item For each territory $e_i$ compute
    \begin{gather*}
      N_b^{ (i) } = \sum_{ j = 1 }^n (1 - \color{ b_j }) \touches{ e_i }{ b_j }\\
      N_w^{ (i) } = \sum_{ j = 1 }^n \color{ b_j } \touches{ e_i }{ b_j }\\
      R_b^{ (i) } = \sum_{ j = 1 }^n (1 - \color{ b_j }) \touches{ e_i }{ b_j } r_j\\
      R_w^{ (i) } = \sum_{ j = 1 }^n \color{ b_j } \touches{ e_i }{ b_j } r_j
    \end{gather*}
  \item Construct the vector
    $$\v{ r }_i = \{ N_b^{ (i) }, N_w^{ (i) }, R_b^{ (i) }, R_w^{ (i) }, \size{ e_i } \}$$
  \item Compute $s_i = \v{ g }[V(\v{ r }_i + \v{ c }) + \v{ d }]$.
  \item Compute $S^* = k - c_b + c_w + \sum_{ i = 1 }^t s_i$.
  \item We will assume that $r_i \neq 0$. Compute
    \begin{gather*}
      D_b = 2 \cdot \sum_{ i = 1 }^n (1 - \color{ b_i }) \size{ b_i } G(r_i)\\
      D_w = 2 \cdot \sum_{ i = 1 }^n \color{ b_i } \size{ b_i } G(r_i)
    \end{gather*}
  \item Output the energy $|S - (S^* + D_b - D_w)|$.
\end{enumerate}
We can write it out algebraically as
\begin{align*}
E(G) &= |E^*(G)| = |S - (S^* + D_b - D_w)|\\
  &= \left|S - \left(k - c_b + c_w + \sum_{ i = 1 }^t s_i\right.\right.\\
  &\left.\left.+ 2 \cdot \sum_{ i = 1 }^n (1 - \color{ b_i }) \size{ b_i } G(r_i)\right.\right.\\
  &\left.\left.- 2 \cdot \sum_{ i = 1 }^n \color{ b_i } \size{ b_i } G(r_i)\right)\right|\\
  &= |S - k + c_b - c_w\\
  &- \sum_{ i = 1 }^t \v{ g } [V(\v{ r }_i + \v{ c }) + \v{ d }]\\\
  &+ 2 \cdot \sum_{ i = 1 }^n \size{ b_i } (\color{ b_i }G(r_i)\\
  &- (1 - \color{ b_i }) G(r_i))|
\end{align*}
Then we find that
\begin{gather*}
\frac{ \partial E^*(G) }{ \partial \v{ g }_i }
  = -\sum_{ k = 1 }^t [V(\v{ r }_k + \v{ c }) + \v{ d }] \frac{ \partial }{ \partial \v{ g }_i } \v{ g }\\
\frac{ \partial E^*(G) }{ \partial V_{ i j } }
  = -\sum_{ k = 1 }^t \v{ g } \left(\frac{ \partial }{ \partial V_{ i j } } V\right)(\v{ r }_k + \v{ c })\\
\frac{ \partial E^*(G) }{ \partial \v{ c }_i }
  = - \sum_{ k = 1 }^t \v{ g } V \frac{ \partial }{ \partial \v{ c }_i } \v{ c }\\
\frac{ \partial E^*(G) }{ \partial \v{ d }_i } = - \sum_{ k = 1 }^t \v{ g } \frac{ \partial }{ \partial \v{ d }_i } \v{ d }
\end{gather*}
Furthermore, since $d G(x) / d x = 0$ then when $r_i \neq 0$
\begin{align*}
\frac{ \partial E^*(G) }{ \partial r_i }
  &= \sum_{ k = 1 }^t \v{ g } V \frac{ \partial }{ \partial r_i } \v{ r }_k\\
  &= \sum_{ k = 1 }^t \v{ g } V
  \left\{ 0, 0, \frac{ \partial }{ \partial r_i } R_b^{ (k) }, \frac{ \partial }{ \partial r_i } R_w^{ (k) }, 0 \right\}
\end{align*}
Therefore,
\begin{gather*}
\frac{ \partial E^*(G) }{ \partial \v{ v }_i } = \sum_{ k = 1 }^t \v{ g } V \{ 0, 0,\\
  \sum_{ j = 1 }^n (1 - \color{ b_j }) \touches{ e_k }{ b_j } [W(\v{ x }_j + \v{ a }) + \v{ b }] \frac{ \partial }{ \partial \v{ v }_i } \v{ v },\\
  \sum_{ j = 1 }^n \color{ b_j } \touches{ e_k }{ b_j } [W(\v{ x }_j + \v{ a }) + \v{ b }]  \frac{ \partial }{ \partial \v{ v }_i } \v{ v }, 0 \}
\end{gather*}
\begin{gather*}
\frac{ \partial E^*(G) }{ \partial W_{ i j } }  = \sum_{ k = 1 }^t \v{ g } V \{ 0, 0,\\
  \sum_{ \ell = 1 }^n (1 - \color{ b_\ell }) \touches{ e_k }{ b_\ell } \v{ v }
  \left(\frac{ \partial }{ \partial W_{ i j } } W\right) (\v{ x }_\ell + \v{ a }),\\
  \sum_{ \ell = 1 }^n \color{ b_\ell } \touches{ e_k }{ b_\ell } \v{ v }
  \left(\frac{ \partial }{ \partial W_{ i j } } W\right) (\v{ x }_\ell + \v{ a }), 0 \}
\end{gather*}
\begin{gather*}
\frac{ \partial E^*(G) }{ \partial \v{ a }_i } = \sum_{ k = 1 }^t \v{ g } V \{ 0, 0,\\
  \sum_{ j = 1 }^n (1 - \color{ b_j }) \touches{ e_k }{ b_j }
  \v{ v } W \frac{ \partial }{ \partial \v{ a }_i } \v{ a },\\
  \sum_{ j = 1 }^n \color{ b_j } \touches{ e_k }{ b_j }
  \v{ v } W \frac{ \partial }{ \partial \v{ a }_i } \v{ a }, 0 \}
\end{gather*}
\begin{gather*}
\frac{ \partial E^*(G) }{ \partial \v{ b }_i } = \sum_{ k = 1 }^t \v{ g } V \{ 0, 0,\\
  \sum_{ j = 1 }^n (1 - \color{ b_j }) \touches{ e_k }{ b_j }
  \v{ v } \frac{ \partial }{ \partial \v{ b }_i } \v{ b },\\
  \sum_{ j = 1 }^n \color{ b_j } \touches{ e_k }{ b_j }
  \v{ v } \frac{ \partial }{ \partial \v{ b }_i } \v{ b }, 0 \}
\end{gather*}
Therefore, we can easily compute the same for $E(G)$ knowing that $d |x| / dx = x / |x|$, i.e. flop signs if $E^*(G) < 0$.
When $E^*(G) = 0$ we set the derivative equal to 0.

The idea behind this algorithm is to first determine an estimate, the $r_i$, as to whether blocks are alive or dead.
Add to the score two times the value of the dead groups (empty territory gained by opponent and capture points).
Then using the life and death information, the empty territories are iterated over and using the L\&D information as
well as the size of the territory a change in score is determined from the territory. For instance, a territory with no
living adjacent black stones should be awarded to white.

We also tried another energy function $E(G) = |S - (S^* + D)|$ where
$$D = 2 \cdot \sum_{ i = 1 }^n \size{ b_i } \colorp{ b_i } r_i$$
where $\colorp{ b }$ returns -1 if $b$ is white and 1 otherwise, but obtained similar results.

\section{Details of Work}

For our program we have programed 5,325 lines of C++. By running {\tt make} one obtains the main program
{\tt gobot}. This program takes in reformatted games in a specific format. This format can be created from {\tt *.sgf}
files by running the Haskell program {\tt reformat} (created by {\tt make reformat} if {\tt ghc} is installed) on individual
files or by running {\tt  reformatGames.sh} on a directory. In case {\tt ghc} is not available we have included
reformatted programs in {\tt reformattedGames.tgz}.

Using {\tt gobot -generate inputDirectory outputDirectory} feature files can be generated for all games in
{\tt inputDirectory} in {\tt outputDirectory}. Or alternatively one can simply run the script
{\tt reformatAndGenerateFeatureFiles.sh} to run both the reformatting and generation procedures in succession.

A model can be trained over a data set using the command
{\tt gobot -train modelFile iterations gameDirectory [featureDirectory]} where {\tt modelFile} is the file to save the
model to, {\tt iterations} is the number of iterations to perform, {\tt gameDirectory} is the location of the games to
train on, and optionally {\tt featureDirectory} is the location of the feature files corresponding to the game (note that
if a game is named {\tt game.sgfo} then the feature file must be named {\tt game.sgfof}).

A model can be tested over a data set using {\tt gobot -test modelFile gameDirectory [featureDirectory]}, whereas
model can predict the score of a single game using {\tt gobot -predict modelFile gameFile [featureFile]}.

Overall in terms of time use the most taxing parts of creating this program were in order feature generation and then
RPROP training. This can be seen just from their files, {\tt src/board.features.cpp} is 1,125 lines long and
{\tt src/rprop.training.cpp} is 1,440 lines long.

\section{Results}

By iterating over the files in a directory rather than reading them all in at once, {\tt gobot} is able to train and test
massive datasets in while using a small amount of memory (under 800kb). Unfortunately because of the complex
nature of the game, specifically the fact that the moves in a game can overlap in the case where a dead group has
previously been removed from the board, it takes a long time to train and test data.

\section{Comparison to Proposal}

\begin{thebibliography}{}

\bibitem[\protect\citename{van der Werf et. al.}2004]{vdW:04}
E.C.D. van der Werf, J. van den Herik, and J.W.H.M. Uiterwijk.
\newblock 2004.
\newblock {\em Learning to score final positions in the game of Go}.
\newblock Advances in Computer Games 10, pages 143-158.
\newblock Kluwer, 2004.

\bibitem[\protect\citename{{Riedmiller and Braun}}1983]{RB:93}
M. Riedmiller and H. Braun.
\newblock 1993.
\newblock {\em A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm}.
\newblock IEEE Int. Conf. on Neural Networks, pages 586-591.
\newblock San Francisco, 1993.

\end{thebibliography}

\end{document}
